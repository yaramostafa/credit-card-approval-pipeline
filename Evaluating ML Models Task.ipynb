{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33b8de6-7d40-4bfa-b4f5-9a24bade79ac",
   "metadata": {},
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09b9ab8-da30-4c44-8759-0472b11ca2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data preprocessing libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Models libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Evaluation libraries\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef85ec-8690-4af3-aadc-83f6f0270c1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Credit card data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fa0120-d006-40a0-b78e-1ac34cc6ea5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Children</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Own_Car</th>\n",
       "      <th>Own_Housing</th>\n",
       "      <th>Credit_Card_Issuing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>40690</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Denied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>75469</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Denied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>70497</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>61000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Denied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>56666</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Denied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_Children  Gender  Income Own_Car Own_Housing Credit_Card_Issuing\n",
       "0             1    Male   40690      No         Yes              Denied\n",
       "1             2  Female   75469     Yes          No              Denied\n",
       "2             1    Male   70497     Yes         Yes            Approved\n",
       "3             1    Male   61000      No          No              Denied\n",
       "4             1    Male   56666     Yes         Yes              Denied"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit_card_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d047bc-4a6d-43ec-a9a7-14a8b5691cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400000 entries, 0 to 399999\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   Num_Children         400000 non-null  int64 \n",
      " 1   Gender               400000 non-null  object\n",
      " 2   Income               400000 non-null  int64 \n",
      " 3   Own_Car              400000 non-null  object\n",
      " 4   Own_Housing          400000 non-null  object\n",
      " 5   Credit_Card_Issuing  400000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e850661-569a-4bfd-b83a-91dcca8161ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Children</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>400000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000892</td>\n",
       "      <td>72517.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.410704</td>\n",
       "      <td>22955.502862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>53336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>72077.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>90669.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>119999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Num_Children         Income\n",
       "count  400000.000000  400000.000000\n",
       "mean        2.000892   72517.997500\n",
       "std         1.410704   22955.502862\n",
       "min         0.000000   30000.000000\n",
       "25%         1.000000   53336.000000\n",
       "50%         2.000000   72077.000000\n",
       "75%         3.000000   90669.000000\n",
       "max        11.000000  119999.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d0808-2f54-4759-b6e5-cc0338d5fd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403ad561-dbf6-4fae-b053-452374e7d2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Num_Children              12\n",
       "Gender                     2\n",
       "Income                 87525\n",
       "Own_Car                    2\n",
       "Own_Housing                2\n",
       "Credit_Card_Issuing        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0779bfde-1d40-48ea-8ae6-443f5c27acb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      200295\n",
       "Female    199705\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_counts = df['Gender'].value_counts()\n",
    "gender_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701969e6-753e-409a-a9ba-3b800299efa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c138d11e-c1bc-4ca8-a320-113d248dc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_cols = ['Gender', 'Own_Car', 'Own_Housing']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('df', OneHotEncoder(), categ_cols)], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a41b3b-14da-480a-9d41-f83a1bc54186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Credit_Card_Issuing'])\n",
    "y = df['Credit_Card_Issuing'] # our target 0: denied, 1: approved\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391bf4a-1d82-465a-bbfa-37408aa0d1b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9f64c9-7e83-48b2-aea9-c05067f2a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f0866c-950a-40a2-b366-f9139f05f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e5b3087-60ac-46ee-bc4e-b3a322b92dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Children</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Own_Car</th>\n",
       "      <th>Own_Housing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>73649</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20731</th>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>44380</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39555</th>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42337</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147506</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>47694</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314215</th>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>60443</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190913</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>92531</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Num_Children  Gender  Income Own_Car Own_Housing\n",
       "23218              4    Male   73649      No          No\n",
       "20731              0  Female   44380      No          No\n",
       "39555              0  Female   42337     Yes          No\n",
       "147506             1    Male   47694      No          No\n",
       "314215             2  Female   60443      No          No\n",
       "190913             2    Male   92531     Yes          No"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836489b8-d703-4cfb-9ad4-4f2dbb598498",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e13122-2216-40e6-ab37-3debaf9de272",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "# svm = SVC(kernel='rbf', C=1.0, probability=True)\n",
    "log_reg = LogisticRegression()\n",
    "xgb = XGBClassifier(use_label_encoder=False)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa13a31-3904-4188-ba32-20e6a4cdc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31691317-f1f2-43fa-994d-12e3bb8ee070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_name, model_instance):\n",
    "    # the pipeline\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('standardization', StandardScaler()),\n",
    "        ('ClassifierModel', model_instance)\n",
    "    ])\n",
    "    \n",
    "    print(\"Training \",model_name)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the trained pipeline to a pkl file (so i can use it with apis)\n",
    "    pipeline_filename = f'{model_name.lower().replace(\" \", \"_\")}_pipeline.pkl'\n",
    "    joblib.dump(model, pipeline_filename)\n",
    "    print(f\"Trained pipeline saved as {pipeline_filename}\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert the predictions back to 'Approved' and 'Denied' if needed\n",
    "    # y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "    \n",
    "    # Evaluate performance on the entire test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\nOverall Model Performance:\")\n",
    "    print(f\"Accuracy for {model_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))  # Using numeric labels\n",
    "    print(\"Predicted labels:\", y_pred[:10]) \n",
    "\n",
    "    # Check classification reports for males and females (Bias/Fairness Evaluation)\n",
    "    male_indices = (X_test['Gender'] == 'Male').values  # Adjust as per your data format\n",
    "    female_indices = (X_test['Gender'] == 'Female').values\n",
    "\n",
    "    y_pred_male = model.predict(X_test[male_indices])\n",
    "    y_true_male = y_test[male_indices]\n",
    "    y_pred_female = model.predict(X_test[female_indices])\n",
    "    y_true_female = y_test[female_indices]\n",
    "\n",
    "    print(\"\\nBias/Fairness Evaluation:\")\n",
    "    print(f\"Male Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_true_male, y_pred_male))\n",
    "    print(f\"Female Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_true_female, y_pred_female))\n",
    "\n",
    "    # Compare training and test performance (Variance)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    print(\"\\nVariance Check:\")\n",
    "    print(f\"Training Accuracy for {model_name}: {train_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy for {model_name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Get feature importances from the model (if supported by model used)\n",
    "    print(\"\\nFeature importances:\")\n",
    "    if hasattr(model.named_steps['ClassifierModel'], 'feature_importances_'):\n",
    "        importances = model.named_steps['ClassifierModel'].feature_importances_\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': importances\n",
    "        }).sort_values(by='Importance', ascending=False)\n",
    "        print(feature_importance_df)\n",
    "    else:\n",
    "        print(f\"{model_name} does not support feature importances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fed7bf26-c570-4583-9992-239f904f666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  Random Forests\n",
      "Trained pipeline saved as random_forests_pipeline.pkl\n",
      "\n",
      "Overall Model Performance:\n",
      "Accuracy for Random Forests: 96.47%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     30931\n",
      "           1       0.97      0.97      0.97     49069\n",
      "\n",
      "    accuracy                           0.96     80000\n",
      "   macro avg       0.96      0.96      0.96     80000\n",
      "weighted avg       0.96      0.96      0.96     80000\n",
      "\n",
      "Predicted labels: [1 1 1 1 1 0 0 0 1 0]\n",
      "\n",
      "Bias/Fairness Evaluation:\n",
      "Male Classification Report for Random Forests:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     22910\n",
      "           1       0.96      0.96      0.96     17045\n",
      "\n",
      "    accuracy                           0.97     39955\n",
      "   macro avg       0.97      0.97      0.97     39955\n",
      "weighted avg       0.97      0.97      0.97     39955\n",
      "\n",
      "Female Classification Report for Random Forests:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      8021\n",
      "           1       0.98      0.98      0.98     32024\n",
      "\n",
      "    accuracy                           0.96     40045\n",
      "   macro avg       0.94      0.94      0.94     40045\n",
      "weighted avg       0.96      0.96      0.96     40045\n",
      "\n",
      "\n",
      "Variance Check:\n",
      "Training Accuracy for Random Forests: 99.77%\n",
      "Test Accuracy for Random Forests: 96.47%\n",
      "\n",
      "Feature importances:\n",
      "                   Feature  Importance\n",
      "7        remainder__Income    0.852797\n",
      "1          df__Gender_Male    0.064172\n",
      "0        df__Gender_Female    0.051963\n",
      "4       df__Own_Housing_No    0.012025\n",
      "5      df__Own_Housing_Yes    0.010605\n",
      "3          df__Own_Car_Yes    0.003526\n",
      "2           df__Own_Car_No    0.002864\n",
      "6  remainder__Num_Children    0.002049\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"Random Forests\", rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2da5cd9-cf88-4058-a448-2af40fafd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(\"Support Vector Machine\", svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d50fa64a-6678-481d-b147-0234ca7d5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  Logistic Regression\n",
      "Trained pipeline saved as logistic_regression_pipeline.pkl\n",
      "\n",
      "Overall Model Performance:\n",
      "Accuracy for Logistic Regression: 97.25%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     30931\n",
      "           1       0.98      0.98      0.98     49069\n",
      "\n",
      "    accuracy                           0.97     80000\n",
      "   macro avg       0.97      0.97      0.97     80000\n",
      "weighted avg       0.97      0.97      0.97     80000\n",
      "\n",
      "Predicted labels: [1 1 1 1 1 0 0 0 1 0]\n",
      "\n",
      "Bias/Fairness Evaluation:\n",
      "Male Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     22910\n",
      "           1       0.97      0.97      0.97     17045\n",
      "\n",
      "    accuracy                           0.97     39955\n",
      "   macro avg       0.97      0.97      0.97     39955\n",
      "weighted avg       0.97      0.97      0.97     39955\n",
      "\n",
      "Female Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      8021\n",
      "           1       0.98      0.98      0.98     32024\n",
      "\n",
      "    accuracy                           0.97     40045\n",
      "   macro avg       0.96      0.95      0.95     40045\n",
      "weighted avg       0.97      0.97      0.97     40045\n",
      "\n",
      "\n",
      "Variance Check:\n",
      "Training Accuracy for Logistic Regression: 97.31%\n",
      "Test Accuracy for Logistic Regression: 97.25%\n",
      "\n",
      "Feature importances:\n",
      "Logistic Regression does not support feature importances.\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"Logistic Regression\", log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5a9764-2f54-4c03-93a1-739f26637b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:46:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained pipeline saved as xgboost_pipeline.pkl\n",
      "\n",
      "Overall Model Performance:\n",
      "Accuracy for XGBoost: 97.24%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     30931\n",
      "           1       0.98      0.98      0.98     49069\n",
      "\n",
      "    accuracy                           0.97     80000\n",
      "   macro avg       0.97      0.97      0.97     80000\n",
      "weighted avg       0.97      0.97      0.97     80000\n",
      "\n",
      "Predicted labels: [1 1 1 1 1 0 0 0 1 0]\n",
      "\n",
      "Bias/Fairness Evaluation:\n",
      "Male Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     22910\n",
      "           1       0.97      0.97      0.97     17045\n",
      "\n",
      "    accuracy                           0.97     39955\n",
      "   macro avg       0.97      0.97      0.97     39955\n",
      "weighted avg       0.97      0.97      0.97     39955\n",
      "\n",
      "Female Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      8021\n",
      "           1       0.98      0.98      0.98     32024\n",
      "\n",
      "    accuracy                           0.97     40045\n",
      "   macro avg       0.96      0.95      0.96     40045\n",
      "weighted avg       0.97      0.97      0.97     40045\n",
      "\n",
      "\n",
      "Variance Check:\n",
      "Training Accuracy for XGBoost: 97.39%\n",
      "Test Accuracy for XGBoost: 97.24%\n",
      "\n",
      "Feature importances:\n",
      "                   Feature  Importance\n",
      "0        df__Gender_Female    0.472414\n",
      "7        remainder__Income    0.346992\n",
      "4       df__Own_Housing_No    0.157003\n",
      "2           df__Own_Car_No    0.023119\n",
      "6  remainder__Num_Children    0.000472\n",
      "1          df__Gender_Male    0.000000\n",
      "3          df__Own_Car_Yes    0.000000\n",
      "5      df__Own_Housing_Yes    0.000000\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"XGBoost\", xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad581469-2b60-46d4-a74d-6956be429333",
   "metadata": {},
   "source": [
    "## Specify how you considered each factor while training the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9b69e-bd01-4603-9883-e724907df2d2",
   "metadata": {},
   "source": [
    "1. Performance: ensure the model accurately predicts whether a credit card application is approved or denied.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "* Used metrics such as accuracy, precision, recall, and F1-score to evaluate the model’s performance on the test set.\n",
    "* Used standardization to ensure that all numerical features have the same scale, which can significantly improve model performance and training stability. Here’s why standardization is important for your task:\n",
    "\n",
    "2. Bias: avoid systematic errors or unfair outcomes for specific groups in the dataset (e.g., gender or income level).\n",
    "\n",
    "Implementation:\n",
    "\n",
    "* Conducted fairness evaluation by calculating separate classification reports for different demographic groups (e.g., male vs. female applicants).\n",
    "* Checked for significant differences in metrics (e.g., precision, recall) between groups to identify potential biases.\n",
    "\n",
    "3. Variance: ensure the model generalizes well and avoids overfitting or underfitting.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "* Evaluated the training vs. test accuracy to identify high variance (overfitting) or high bias (underfitting).\n",
    "* Used cross-validation to ensure the model performs consistently across different data splits.\n",
    "* Applied regularization in models like Logistic Regression and set a limit on tree depth in models like Random Forest to prevent overfitting.\n",
    "\n",
    "4. Fairness: ensure the model makes fair predictions across different demographic groups (e.g., gender or income levels).\n",
    "\n",
    "Implementation:\n",
    "\n",
    "* After training, evaluated the model separately for male and female applicants using metrics like accuracy, precision, and recall.\n",
    "* Compared false-positive and false-negative rates for different groups to detect any disparities.\n",
    "\n",
    "5. Model Interpretability:\n",
    "make the model’s decision-making process transparent and understandable.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "* For interpretable models like Logistic Regression, inspected feature coefficients to understand which features contribute most to the predictions.\n",
    "* For models like Random Forest, extracted feature importances to determine the most influential factors in decision-making.\n",
    "* Documented how preprocessing steps (e.g., one-hot encoding) and feature transformations affect model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ee3a1-ad4d-4815-b716-a601fb48a16f",
   "metadata": {},
   "source": [
    "## Chosen model based on my analysis\n",
    "\n",
    "- Accuracy:\n",
    "\n",
    "Logistic Regression and XGBoost have the highest test accuracy (97.25% and 97.24%, respectively) with Random Forest slightly behind at 96.47%.\n",
    "\n",
    "- Variance:\n",
    "\n",
    "Logistic Regression shows minimal variance between training and test accuracies (97.31% vs. 97.25%) that means it generalizes well.\n",
    "XGBoost also has low variance (97.39% vs. 97.24%).\n",
    "Random Forest shows a higher gap between training (99.77%) and test accuracy (96.47%) indicating slightly overfitting.\n",
    "\n",
    "- Bias (Gender Fairness):\n",
    "\n",
    "All models show similar performance for male and female groups but Logistic Regression and XGBoost have slightly better fairness scores compared to Random Forest.\n",
    "\n",
    "- Overfitting:\n",
    "\n",
    "Random Forest has a higher risk of overfitting due to its very high training accuracy compared to test accuracy.\n",
    "\n",
    "**Best Model: Logistic Regression**\n",
    "It has the highest test accuracy, minimal variance, excellent fairness, and high interpretability. It is also straightforward to implement and understand which with the task's focus on performance, fairness, and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca0ca0-b577-4ff0-b78e-ad3fecc740ec",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61032881-73cb-4d85-8987-7f5ba4a68328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "150 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1182, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\yara.maraey\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.97302813 0.97308125 0.97303437 0.97304375        nan        nan\n",
      " 0.97303437 0.97309375 0.97303437 0.97304062        nan        nan\n",
      " 0.97302188 0.9730875  0.97303437 0.97303437        nan        nan\n",
      " 0.9731     0.97309687 0.97304687 0.9730875         nan        nan\n",
      " 0.97309375 0.9730875  0.97304687 0.97308438        nan        nan\n",
      " 0.97309688 0.973075   0.97304687 0.97308125        nan        nan\n",
      " 0.973075   0.97306562 0.97307813 0.9730625         nan        nan\n",
      " 0.97308125 0.97308438 0.97307813 0.97307813        nan        nan\n",
      " 0.97308125 0.97306875 0.97307813 0.97307187        nan        nan\n",
      " 0.97307187 0.973075   0.973075   0.973075          nan        nan\n",
      " 0.97306875 0.97308438 0.973075   0.97307813        nan        nan\n",
      " 0.973075   0.97307813 0.973075   0.973075          nan        nan\n",
      " 0.97307187 0.973075   0.97307187 0.97307187        nan        nan\n",
      " 0.97307187 0.97306875 0.97307187 0.97307187        nan        nan\n",
      " 0.97307187 0.9730875  0.97307187 0.97307813        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'Logistic Regression__C': 0.1, 'Logistic Regression__max_iter': 100, 'Logistic Regression__penalty': 'l1', 'Logistic Regression__solver': 'liblinear'}\n",
      "Best Cross-Validation Accuracy: 0.9731\n",
      "Test Accuracy of Best Logistic Regression Model: 0.97255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Parameter grid \n",
    "param_grid = {\n",
    "    'Logistic Regression__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'Logistic Regression__C': [0.01, 0.1, 1, 10, 100],  # regularization strength\n",
    "    'Logistic Regression__solver': ['liblinear', 'saga'],  \n",
    "    'Logistic Regression__max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(Pipeline([('preprocessor', preprocessor),('scaler', StandardScaler()),('Logistic Regression', LogisticRegression())]),\n",
    "                           param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and best score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of Best Logistic Regression Model:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dff3ab9c-d78e-4a6f-9bc9-674901efede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Coefficient  Absolute Importance\n",
      "7        remainder__Income   -17.637697            17.637697\n",
      "0        df__Gender_Female     2.370470             2.370470\n",
      "5      df__Own_Housing_Yes    -1.689537             1.689537\n",
      "1          df__Gender_Male    -1.479290             1.479290\n",
      "4       df__Own_Housing_No     0.956643             0.956643\n",
      "3          df__Own_Car_Yes    -0.606268             0.606268\n",
      "2           df__Own_Car_No     0.463366             0.463366\n",
      "6  remainder__Num_Children     0.009551             0.009551\n"
     ]
    }
   ],
   "source": [
    "coefficients = best_model.named_steps['Logistic Regression'].coef_[0]\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Absolute Importance': np.abs(coefficients)\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Absolute Importance', ascending=False)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb38f9-4f62-4891-af2c-813187ce00c3",
   "metadata": {},
   "source": [
    "df__Gender_Female (2.71) is an indication that the model might be favoring females potentially introducing a gender bias. However performing better than the other 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d9eba33-c04e-4460-86ae-3ae8e126b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_tuned = LogisticRegression(C=0.1, penalty=\"l1\", solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b4e1d1a-657c-4fa8-80c8-6889a67b523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  Logistic Regression Tuned\n",
      "Trained pipeline saved as logistic_regression_tuned_pipeline.pkl\n",
      "\n",
      "Overall Model Performance:\n",
      "Accuracy for Logistic Regression Tuned: 97.25%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     30931\n",
      "           1       0.98      0.98      0.98     49069\n",
      "\n",
      "    accuracy                           0.97     80000\n",
      "   macro avg       0.97      0.97      0.97     80000\n",
      "weighted avg       0.97      0.97      0.97     80000\n",
      "\n",
      "Predicted labels: [1 1 1 1 1 0 0 0 1 0]\n",
      "\n",
      "Bias/Fairness Evaluation:\n",
      "Male Classification Report for Logistic Regression Tuned:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     22910\n",
      "           1       0.97      0.97      0.97     17045\n",
      "\n",
      "    accuracy                           0.97     39955\n",
      "   macro avg       0.97      0.97      0.97     39955\n",
      "weighted avg       0.97      0.97      0.97     39955\n",
      "\n",
      "Female Classification Report for Logistic Regression Tuned:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      8021\n",
      "           1       0.98      0.98      0.98     32024\n",
      "\n",
      "    accuracy                           0.97     40045\n",
      "   macro avg       0.96      0.95      0.95     40045\n",
      "weighted avg       0.97      0.97      0.97     40045\n",
      "\n",
      "\n",
      "Variance Check:\n",
      "Training Accuracy for Logistic Regression Tuned: 97.31%\n",
      "Test Accuracy for Logistic Regression Tuned: 97.25%\n",
      "\n",
      "Feature importances:\n",
      "Logistic Regression Tuned does not support feature importances.\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"Logistic Regression Tuned\", log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f96cf7b-342b-4017-8818-ebbf8126f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0]\n"
     ]
    }
   ],
   "source": [
    "# test pkl file\n",
    "pipeline = joblib.load('logistic_regression_tuned_pipeline.pkl')\n",
    "new_data = pd.DataFrame({\n",
    "    'Num_Children': [2],\n",
    "    'Gender': ['Male'],\n",
    "    'Income': [92531],\n",
    "    'Own_Car': ['No'],\n",
    "    'Own_Housing': ['No']\n",
    "})\n",
    "\n",
    "predictions = pipeline.predict(new_data)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3243b0-6f6a-4fd9-9828-da7e1a5fc513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
